# Multi-Agent Reinforcement Learning Simulator

## Overview

This project is a Multi-Agent Reinforcement Learning Simulator that leverages the CerebrasLLM model for generating responses. The simulator includes a custom Gym environment for multi-agent reinforcement learning, a web interface for interaction, and various agents with distinct roles and tools.

## Setup Instructions

1. Clone the repository:
   ```bash
   git clone https://github.com/kinghendrix10/Multi-Agent-Reinforcement-Learning.git
   cd Multi-Agent-Reinforcement-Learning
   ```

2. Create and activate a virtual environment:
   ```bash
   python3 -m venv venv
   source venv/bin/activate  # On Windows use `venv\Scripts\activate`
   ```

3. Install the required dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Set up environment variables:
   - Create a `.env` file in the root directory.
   - Add your Cerebras API key to the `.env` file:
     ```
     CEREBRAS_API_KEY=your_api_key_here
     ```

## Usage Guidelines

1. Start the Flask application:
   ```bash
   flask run
   ```

2. Open your web browser and navigate to `http://localhost:5000`.

3. Enter the task and number of cycles in the web interface and start the simulation.

4. View the conversation log and final report generated by the agents.

## Configuration Options

The `config.yaml` file contains the configuration options for the environment and agents. Below are the details:

### Environment Configuration
```yaml
environment:
  num_agents: 4
  max_steps: 100
```
- `num_agents`: Number of agents in the environment.
- `max_steps`: Maximum number of steps in each simulation.

### Agents Configuration
```yaml
agents:
  - name: Researcher
    role: Gather and analyze information
    tools: 
      - Internet access
      - Data analysis software
  - name: Planner
    role: Create and optimize strategies
    tools:
      - Project management software
      - Decision-making algorithms
  - name: Executor
    role: Implement plans and monitor progress
    tools:
      - Task automation tools
      - Progress tracking software
  - name: Critic
    role: Evaluate outcomes and suggest improvements
    tools:
      - Evaluation frameworks
      - Feedback analysis tools
```
- `name`: Name of the agent.
- `role`: Role of the agent.
- `tools`: Tools available to the agent.

### Simulation Configuration
```yaml
simulation:
  num_cycles: 10
```
- `num_cycles`: Number of cycles in the simulation.

## Dependencies

The project requires the following dependencies, as listed in `requirements.txt`:
- `flask`
- `gym`
- `numpy`
- `transformers`
- `torch`
- `pyyaml`
- `cerebras-cloud-sdk`
- `ray[rllib]`
- `groq`
- `python-dotenv`
- `flask-socketio`

## Main Components

### `main.py`
The main application logic that initializes agents and the environment, and runs the simulation.

### `agent.py`
Defines the `LLMAgent` class, which uses the `CerebrasLLM` model for generating responses.

### `environment.py`
Defines the `MultiAgentEnv` class, a custom Gym environment for multi-agent reinforcement learning.

### `llm_model.py`
Contains the `CerebrasLLM` class for interacting with the Cerebras API.

### Static Files
- `static/css/style.css`: CSS styles for the web interface.
- `static/js/script.js`: JavaScript for the web interface.

### Templates
- `templates/index.html`: HTML structure for the web interface.
